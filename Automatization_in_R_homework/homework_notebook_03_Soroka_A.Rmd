---
title: "automatization_notebook_03"
output:
  html_document:
    df_print: paged
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(readr)
library(psych)
library(tibble)


```

# Чтение данных

В вашем варианте нужно использовать датасет framingham.

```{r}
df= readr::read_csv('Data/framingham.csv', col_types = "iiiiiiiiiidddiii" )
spec(df)

```

# Выведите общее описание данных

```{r}

df_description <- df %>%
  glimpse()

df_description_2 <- describe(df, na.rm = TRUE, skew = FALSE, ranges = TRUE)
print(df_description_2)
```

# Очистка данных

1) Уберите переменные, в которых пропущенных значений больше 20% или уберите субъектов со слишком большим количеством пропущенных значений. Или совместите оба варианта. Напишите обоснование, почему вы выбрали тот или иной вариант:
```{r}


na_count_cols <- colSums(is.na(df))
na_count_cols #Сколько N/A в каждом столбце

percent_na_glucose <- na_count_cols["glucose"] / nrow(df) * 100
percent_na_glucose #Процент N/A в переменной glucose


na_count_rows <- df %>%
  rowwise() %>%
  mutate(na_count = sum(is.na(c_across(everything()))))

na_count_rows_summary <- na_count_rows %>%
  count(na_count)
na_count_rows_summary #Количество строк в датасете с разным количеством N/A

df_clean <- df %>%
  filter(rowSums(is.na(.)) < 2) #Чистим датасет, чтобы в одной строке не было двух и более NA


```

**Обоснование**: 
###Переменных, в которых было бы больше 20% N/A, в датасете нет. Больше всего пропущенно значений в глюкозе (9,15%). Всего в 645 строках пропущены значения. Максимальное число пропущенных значений у одного субъекта - 3 (и таких субъектов всего два). Были удалены строки с двумя и тремя пропущенными значениями.

2) Переименуйте переменные в человекочитаемый вид (что делать с пробелами в названиях?);
```{r}
library(stringi)
df_clean <- df_clean %>%
  rename_with(function(x) x %>% stri_replace_all_regex(c("male", "age", "education", "currentSmoker", "cigsPerDay", "BPMeds", "prevalentStroke", "prevalentHyp", "diabetes", "totChol", "sysBP", "diaBP", "BMI", "heartRate", "glucose", "TenYearCHD"), c("Мужской пол", "Возраст", "Образование", "Курит", "Сигарет в день", "Антигипертоническая терапия", "Инсульт", "Гипертензия", "Диабет", "Общий холестерол", "АД-систолическое", "АД-диастолическое", "Индекс массы тела", "Частота сердцебиения", "Глюкоза", "Риск CDH"), vectorise_all = FALSE)) %>%
  glimpse()
```

3) В соответствии с описанием данных приведите переменные к нужному типу (numeric или factor);
```{r}
df_clean <- df_clean %>%
  mutate(`Мужской пол` = factor(`Мужской пол`, levels = c(0, 1), labels = c("Нет", "Да")), Образование = as.factor(Образование), Курит = as.factor(Курит), `Антигипертоническая терапия` = as.factor(`Антигипертоническая терапия`), Инсульт = as.factor(Инсульт), Гипертензия = as.factor(Гипертензия), Диабет = as.factor(Диабет), `Риск CDH` = as.factor(`Риск CDH`))

str(df_clean)
```

4) Отсортируйте данные по возрасту по убыванию;
```{r}
df_clean <- df_clean %>%
  arrange(desc(`Возраст`))
```

5) Сохраните в файл outliers.csv субъектов, которые являются выбросами (например, по правилу трёх сигм) — это необязательное задание со звёздочкой;
```{r}
df_clean <- df_clean %>%
  mutate(`ID` = row_number())

numeric_vars <- df_clean %>%
  select_if(is.numeric) %>%
  names()

outliers_list <- list() #список для хранения выбросов

for (var in numeric_vars) {
  mean_value <- mean(df_clean[[var]], na.rm = TRUE)
  std_value <- sd(df_clean[[var]], na.rm = TRUE)
  lower_bound <- mean_value - 3 * std_value
  upper_bound <- mean_value + 3 * std_value
  outliers_data <- df_clean %>%
    filter((!!sym(var) < lower_bound) | (!!sym(var) > upper_bound))
  outliers_list[[var]] <- outliers_data
}

all_outliers <- bind_rows(outliers_list) %>%
  distinct()

df_outliers <- write.csv(all_outliers, "outliers.csv", row.names = FALSE)
str(all_outliers)
```

6) Присвойте получившийся датасет переменной "cleaned_data".

```{r}
cleaned_data <- df_clean %>%
  anti_join(all_outliers, by = "ID") #удаляем все строки с выбросами

cleaned_data <- cleaned_data %>%
  select(-ID)

str(cleaned_data)

```

# Сколько осталось переменных?

```{r}

nrow(cleaned_data)

```

# Сколько осталось случаев?

```{r}

CDH_cases <- sum(cleaned_data$`Риск CDH`==1)
CDH_cases

```

# Есть ли в данных идентичные строки?

```{r}

identical_rows <- cleaned_data[duplicated(cleaned_data), ]
identical_rows
unique_data <- cleaned_data %>% distinct()
unique_data #Строк столько же, значит все строки уникальные


```

# Сколько всего переменных с пропущенными значениями в данных и сколько пропущенных точек в каждой такой переменной?

```{r}
missing_summary <- cleaned_data %>% 
  summarize(
    vars_with_missing = sum(across(everything(), ~is.na(.))),
    missing_per_variable = across(everything(), ~sum(is.na(.)))
  )

print(missing_summary$vars_with_missing) #Всего 495 N/A
print(missing_summary$missing_per_variable) #N/A в каждой переменной

```

# Описательные статистики

## Количественные переменные

1) Рассчитайте для всех количественных переменных для каждой группы (TenYearCHD):

1.1) Количество значений;

1.2) Количество пропущенных значений;

1.3) Среднее;

1.4) Медиану;

1.5) Стандартное отклонение;

1.6) 25% квантиль и 75% квантиль;

1.7) Интерквартильный размах;

1.8) Минимум;

1.9) Максимум;

1.10) 95% ДИ для среднего - задание со звёздочкой.

```{r}

numeric_vars <- cleaned_data %>%
  select_if(is.numeric) %>%
  names()

# Список функций для расчета статистики
statistics <- list(
  `Количество значений` = ~length(.x),
  `Количество пропущенных значений` = ~sum(is.na(.x)),
  `Среднее значение` = ~ifelse(sum(!is.na(.x)) == 0, "Н/П*", mean(.x, na.rm = TRUE) %>% round(2) %>% as.character()),
  `Медиана` = ~ifelse(sum(!is.na(.x)) == 0, "Н/П*", median(.x, na.rm = TRUE) %>% round(2) %>% as.character()),
  `Станд. отклон.` = ~ifelse(sum(!is.na(.x)) < 3, "Н/П*", sd(.x, na.rm = TRUE) %>% round(2) %>% as.character()),
  `мин. - макс.` = ~ifelse(sum(!is.na(.x)) == 0, "Н/П*", paste0(min(.x, na.rm = TRUE) %>% round(2), " - ", max(.x, na.rm = TRUE) %>% round(2))),
  `95% ДИ для среднего` = ~ifelse(sum(!is.na(.x)) == 0, "Н/П*", paste0((mean(.x, na.rm = TRUE) - qnorm(0.975) * (sd(.x, na.rm = TRUE)/sqrt(length(.x)))) %>% round(2), " - ", (mean(.x, na.rm = TRUE) + qnorm(0.975) * (sd(.x, na.rm = TRUE)/sqrt(length(.x)))) %>% round(2))),
  `Интерквартильный размах` = ~quantile(.x, 0.75, na.rm = TRUE) - quantile(.x, 0.25, na.rm = TRUE)
)

# Расчет статистики для каждой числовой переменной, сгруппированной по `Риск CDH`

df_statistics_numeric <- cleaned_data %>%
  group_by(`Риск CDH`) %>%
  summarise(across(all_of(numeric_vars), statistics, .names = "{.fn}__{.col}")) %>%
  mutate(across(everything(), as.character)) %>%  
  pivot_longer(
    cols = -`Риск CDH`,
    names_to = c("Статистика", "Переменная"),
    names_sep = "__",  
    values_to = "Value"
  )

print(df_statistics_numeric)
```

## Категориальные переменные

1) Рассчитайте для всех категориальных переменных для каждой группы (TenYearCHD):

1.1) Абсолютное количество;

1.2) Относительное количество внутри группы;

1.3) 95% ДИ для доли внутри группы - задание со звёздочкой.

```{r}
categorical_vars <- cleaned_data %>% 
  select_if(is.factor) %>% 
  select(-`Риск CDH`) %>%  
  names()


df_statistics_categoric <- cleaned_data %>%
  select(all_of(categorical_vars), `Риск CDH`) %>%
  pivot_longer(cols = all_of(categorical_vars), names_to = "Переменная", values_to = "Значение") %>%
  group_by(`Риск CDH`, Переменная, Значение) %>%
  summarise(`Абсолютное количество` = n(), .groups = "drop") %>%
  mutate(`Относительное количество` = `Абсолютное количество` / sum(`Абсолютное количество`))

df_statistics_categoric

```

# Визуализация

## Количественные переменные

1) Для каждой количественной переменной сделайте боксплоты по группам. Расположите их либо на отдельных рисунках, либо на одном, но читаемо;

2) Наложите на боксплоты beeplots - задание со звёздочкой.

3) Раскрасьте боксплоты с помощью библиотеки RColorBrewer.

```{r}
library(RColorBrewer)

df_long <- cleaned_data %>%
  pivot_longer(cols = all_of(numeric_vars), names_to = "Переменная", values_to = "Значение")

plot_list <- lapply(numeric_vars, function(x) {
  ggplot(df_long[df_long$Переменная == x, ], aes(x = `Риск CDH`, y = Значение, fill = `Риск CDH`)) +
    geom_boxplot() +
    labs(title = x, y = "Значение") +
    theme_minimal()
})

# Отображение графиков
lapply(plot_list, print)

```

## Категориальные переменные

1) Сделайте подходящие визуализации категориальных переменных. Обоснуйте, почему выбрали именно этот тип.

```{r}




```


# Статистические оценки

## Проверка на нормальность

1) Оцените каждую переменную на соответствие нормальному распределению с помощью теста Шапиро-Уилка. Какие из переменных являются нормальными и как как вы это поняли?

```{r}
shapiro_results <- numeric(length(numeric_vars))
numeric_vars_2 <- numeric_vars[numeric_vars != "ID"]

names(shapiro_results) <- numeric_vars_2

for (var in numeric_vars_2) {
if (var!="ID") {
  data <- na.omit(cleaned_data[[var]])
  
  shapiro_results[var] <- shapiro.test(data)$p.value
}
}

print(shapiro_results)


#По результатам Шапиро-Уилка здесь нет нормально распределенных переменных

```

2) Постройте для каждой количественной переменной QQ-плот. Отличаются ли выводы от теста Шапиро-Уилка? Какой метод вы бы предпочли и почему?

```{r}
plot_qq <- function(data, var_name) {
  ggplot(data, aes(sample = !!sym(var_name))) +
    geom_qq() +
    geom_qq_line(color = "red") +
    ggtitle(paste("QQ-Plot для переменной", var_name)) +
    theme_minimal()
}

# Применяем функцию к каждой количественной переменной
for (var in numeric_vars) {
  print(plot_qq(df_clean, var))
}

#На QQ-плоте некоторые переменные кажутся вполне нормально распределенными с небольшими отклонениями на концах. Например, переменные с давлением, частотой сердцебиения, в то время как тест Шапиро-Уилка однозначно определяет их как не нормально распределенные. Лучше использовать комбинацию методов для оценки характера распределения.

```

3) Ниже напишите, какие ещё методы проверки на нормальность вы знаете и какие у них есть ограничения.

**Напишите текст здесь**
Можно просто сравнить форму гистограммы данного распределения с формой нормального распределения, ограничение в неточности и примерности.
Также есть другие статистические тесты. Например, тест Колмогорова-Сирнова (этот тест менее мощный, то есть с меньшей вероятностью отвергнуть нулевую гипотезу, когда альтернативная верна)

## Сравнение групп

1) Сравните группы (переменная **TenYearCHD**) по каждой переменной (как количественной, так и категориальной). Для каждой переменной выберите нужный критерий и кратко обоснуйте его выбор в комментариях.

```{r}
#Количественные
num_results_df <- data.frame(variable = character(), p.value = numeric())

#тест Манна-Уитни
for (var in numeric_vars) {
  group1 <- subset(cleaned_data, `Риск CDH` == 0)[[var]]
  group2 <- subset(cleaned_data, `Риск CDH` == 1)[[var]]
  
  test_result <- wilcox.test(group1, group2)
  
  num_results_df <- rbind(num_results_df, data.frame(variable = var, p.value = test_result$p.value))
}


significant_vars <- num_results_df[num_results_df$p.value < 0.05, "variable"]
significant_vars

num_results_df

#Группы риска CDH статистически значимо различаются по уровню 0.05 по следующим переменным: Возраст, Сигарет в день, Общий холестерол, АД-систолическое, АД-диастолическое, Индекс массы тела.

```
```{r}

#Категориальные
chi2_results <- data.frame(variable = character(), p.value = numeric())

# Проходим по каждой категориальной переменной и проводим тест Хи-квадрат
for (var in categorical_vars) {
  table_data <- table(cleaned_data[[var]], cleaned_data$`Риск CDH`)
  
  # Проверяем условие ожидаемого количества наблюдений > 5
  if (all(chisq.test(table_data)$expected >= 5)) {
    test_result <- chisq.test(table_data)
    chi2_results <- rbind(chi2_results, data.frame(variable = var, p.value = test_result$p.value))
  } else {
    chi2_results <- rbind(chi2_results, data.frame(variable = var, p.value = NA))
  }
}

significant_vars_2 <- chi2_results[chi2_results$p.value < 0.05, "variable"]
significant_vars_2

chi2_results

#Группы риска CDH статистически значимо различаются по уровню 0.05 по следующим переменным:Мужской пол, Образование, Антигипертоническая терапия, Гипертензия.
```

# Далее идут **необязательные** дополнительные задания, которые могут принести вам дополнительные баллы в том числе в случае ошибок в предыдущих

## Корреляционный анализ

1) Создайте корреляционную матрицу с визуализацией и поправкой на множественные сравнения. Объясните, когда лучше использовать корреляционные матрицы и в чём минусы и плюсы корреляционных исследований.

```{r}
#install.packages("corrplot")
library(corrplot)
cleaned_data_num <- cleaned_data %>%
  select(where(is.numeric)) 

df_cor <- cor(cleaned_data_num, use = "complete.obs")
adjusted_df_cor <- p.adjust(df_cor, method = "bonferroni")

corrplot(df_cor, method = 'number', number.cex = 1, tl.cex = 0.8)

#Корреляционные матрицы нужны для оценки взаимосвязи переменных, корреляционный анализ можно использовать для первичного анализа, чтобы лучше понять структуру данных и подготовить к дальнейшему статистическому анализу. Минусы в том, что корреляция не означает причинно-следственных связей, такой анализ может быть чувствителен к выбросам.

```



## Моделирование

1) Постройте регрессионную модель для переменной **TenYearCHD**. Опишите процесс построения

```{r}

#Риск CDH - категориальная биномиальная переменная, для которой можно применить логистическую регрессию


model <- glm(`Риск CDH` ~ `Возраст` + `Мужской пол` + `Общий холестерол`, 
            data = cleaned_data, 
            family = "binomial")
summary(model)

model2 <- glm(`Риск CDH` ~ ., 
            data = cleaned_data, 
            family = "binomial")
summary(model2)


# Переменные Мужской пол, Возраст, Сигарет в день и АД-систолическое имеют p-value меньше 0.05, что делает их статистически значимыми.
```




